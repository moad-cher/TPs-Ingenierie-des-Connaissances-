{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d56844f",
   "metadata": {},
   "source": [
    "<style>\n",
    "h1{font-family: 'lucida handwriting'}\n",
    "</style>\n",
    "<center>\n",
    "\n",
    "# **TP**<br> ontologie\n",
    "</center>\n",
    "\n",
    "### **CHERGUI Moad**  \n",
    "IID3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b1c843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import spacy\n",
    "\"\"\"\"\n",
    "import spacy.cli\n",
    "spacy.cli.download(\"en_core_web_sm\")\n",
    "#\"\"\"\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "texte = \"There are courses and laboratory courses. Homeworks are part of courses. Courses are organized by teachers. Teachers are either professors or assistants. Professors teach courses while assistants only teach laboratory courses.\"\n",
    "doc = nlp(texte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6d67642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "concepts = set()\n",
    "relations = []\n",
    "\n",
    "# Extraction des concepts (noms propres + noms communs importants)\n",
    "for token in doc:\n",
    "    if token.pos_ in [\"PROPN\", \"NOUN\"]:\n",
    "        concepts.add(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fde5254b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concepts extracted from text:\n",
      "- Courses\n",
      "- Homeworks\n",
      "- Professors\n",
      "- Teachers\n",
      "- assistants\n",
      "- courses\n",
      "- laboratory\n",
      "- part\n",
      "- professors\n",
      "- teachers\n",
      "\n",
      "Relations extracted from text:\n",
      "Homeworks --be--> part\n",
      "Courses --organize by--> teachers\n",
      "Teachers --be--> professors\n",
      "Professors --teach--> courses\n",
      "assistants --teach--> courses\n"
     ]
    }
   ],
   "source": [
    "relations = []\n",
    "for token in doc:\n",
    "    if token.pos_ in ['VERB', 'AUX']:\n",
    "        subj = None\n",
    "        obj = None\n",
    "        prep = None\n",
    "        for child in token.children:\n",
    "            if child.dep_ in ['nsubj', 'nsubjpass']:\n",
    "                subj = child.text\n",
    "            elif child.dep_ in ['dobj', 'attr']:\n",
    "                obj = child.text\n",
    "            elif child.dep_ in ['prep', 'agent']:\n",
    "                prep = child.text\n",
    "                for gchild in child.children:\n",
    "                    if gchild.dep_ == 'pobj':\n",
    "                        obj = gchild.text\n",
    "                        break\n",
    "        if subj and obj:\n",
    "            relation = token.lemma_\n",
    "            if prep:\n",
    "                relation += ' ' + prep\n",
    "            relations.append((subj, relation, obj))\n",
    "\n",
    "# Affichage\n",
    "print(\"Concepts extracted from text:\")\n",
    "for c in sorted(concepts):\n",
    "    print(\"-\", c)\n",
    "\n",
    "print(\"\\nRelations extracted from text:\")\n",
    "for s, v, o in relations:\n",
    "    print(f\"{s} --{v}--> {o}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "be5947cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nf770ab3d618d4a7b842d376250ae9093 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph, Namespace, RDF, RDFS\n",
    "\n",
    "# Cr√©ation du graphe\n",
    "g = Graph()\n",
    "EX = Namespace(\"http://example.org/ontology/\")\n",
    "\n",
    "g.bind(\"ex\", EX)\n",
    "\n",
    "# ======================\n",
    "# Classes based on extracted concepts\n",
    "# ======================\n",
    "g.add((EX.Course, RDF.type, RDFS.Class))\n",
    "g.add((EX.Homework, RDF.type, RDFS.Class))\n",
    "g.add((EX.Teacher, RDF.type, RDFS.Class))\n",
    "g.add((EX.Professor, RDF.type, RDFS.Class))\n",
    "g.add((EX.Assistant, RDF.type, RDFS.Class))\n",
    "g.add((EX.LaboratoryCourse, RDF.type, RDFS.Class))\n",
    "\n",
    "# Hierarchy based on text\n",
    "g.add((EX.Professor, RDFS.subClassOf, EX.Teacher))\n",
    "g.add((EX.Assistant, RDFS.subClassOf, EX.Teacher))\n",
    "g.add((EX.LaboratoryCourse, RDFS.subClassOf, EX.Course))\n",
    "\n",
    "# ======================\n",
    "# Properties based on extracted relations\n",
    "# ======================\n",
    "g.add((EX.partOf, RDF.type, RDF.Property))\n",
    "g.add((EX.organizedBy, RDF.type, RDF.Property))\n",
    "g.add((EX.teach, RDF.type, RDF.Property))\n",
    "\n",
    "# Domains and ranges\n",
    "g.add((EX.partOf, RDFS.domain, EX.Homework))\n",
    "g.add((EX.partOf, RDFS.range, EX.Course))\n",
    "\n",
    "g.add((EX.organizedBy, RDFS.domain, EX.Course))\n",
    "g.add((EX.organizedBy, RDFS.range, EX.Teacher))\n",
    "\n",
    "g.add((EX.teach, RDFS.domain, EX.Teacher))\n",
    "g.add((EX.teach, RDFS.range, EX.Course))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b4ef92d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ontology file ontology.ttl created successfully\n"
     ]
    }
   ],
   "source": [
    "g.serialize(\"ontology.ttl\", format=\"turtle\")\n",
    "print(\"Ontology file ontology.ttl created successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
